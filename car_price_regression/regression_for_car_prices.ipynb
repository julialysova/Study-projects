{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Оглавление<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка-данных\" data-toc-modified-id=\"Подготовка-данных-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка данных</a></span></li><li><span><a href=\"#Обучение-моделей\" data-toc-modified-id=\"Обучение-моделей-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение моделей</a></span></li><li><span><a href=\"#Анализ-моделей\" data-toc-modified-id=\"Анализ-моделей-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Анализ моделей</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Определение стоимости автомобилей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сервис по продаже автомобилей с пробегом разрабатывает приложение для привлечения новых клиентов. В нём можно быстро узнать рыночную стоимость своего автомобиля. В нашем распоряжении исторические данные: технические характеристики, комплектации и цены автомобилей. Нам нужно построить модель для определения стоимости. \n",
    "\n",
    "Заказчику важны:\n",
    "\n",
    "- качество предсказания;\n",
    "- скорость предсказания;\n",
    "- время обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загружаем библиотеки\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первым делом подготовим данные. Загрузим их и посмотрим на пропуски или аномалии. Далее постараемся их исправить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('autos.csv')\n",
    "except:\n",
    "    data = pd.read_csv('/datasets/autos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 354369 entries, 0 to 354368\n",
      "Data columns (total 16 columns):\n",
      "DateCrawled          354369 non-null object\n",
      "Price                354369 non-null int64\n",
      "VehicleType          316879 non-null object\n",
      "RegistrationYear     354369 non-null int64\n",
      "Gearbox              334536 non-null object\n",
      "Power                354369 non-null int64\n",
      "Model                334664 non-null object\n",
      "Kilometer            354369 non-null int64\n",
      "RegistrationMonth    354369 non-null int64\n",
      "FuelType             321474 non-null object\n",
      "Brand                354369 non-null object\n",
      "NotRepaired          283215 non-null object\n",
      "DateCreated          354369 non-null object\n",
      "NumberOfPictures     354369 non-null int64\n",
      "PostalCode           354369 non-null int64\n",
      "LastSeen             354369 non-null object\n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 43.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateCrawled</th>\n",
       "      <th>Price</th>\n",
       "      <th>VehicleType</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>Power</th>\n",
       "      <th>Model</th>\n",
       "      <th>Kilometer</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>FuelType</th>\n",
       "      <th>Brand</th>\n",
       "      <th>NotRepaired</th>\n",
       "      <th>DateCreated</th>\n",
       "      <th>NumberOfPictures</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>LastSeen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2016-03-24 11:52:17</td>\n",
       "      <td>480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993</td>\n",
       "      <td>manual</td>\n",
       "      <td>0</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-24 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>70435</td>\n",
       "      <td>2016-04-07 03:16:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-24 10:58:45</td>\n",
       "      <td>18300</td>\n",
       "      <td>coupe</td>\n",
       "      <td>2011</td>\n",
       "      <td>manual</td>\n",
       "      <td>190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125000</td>\n",
       "      <td>5</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>audi</td>\n",
       "      <td>yes</td>\n",
       "      <td>2016-03-24 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>66954</td>\n",
       "      <td>2016-04-07 01:46:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-14 12:52:21</td>\n",
       "      <td>9800</td>\n",
       "      <td>suv</td>\n",
       "      <td>2004</td>\n",
       "      <td>auto</td>\n",
       "      <td>163</td>\n",
       "      <td>grand</td>\n",
       "      <td>125000</td>\n",
       "      <td>8</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>jeep</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-14 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>90480</td>\n",
       "      <td>2016-04-05 12:47:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2016-03-17 16:54:04</td>\n",
       "      <td>1500</td>\n",
       "      <td>small</td>\n",
       "      <td>2001</td>\n",
       "      <td>manual</td>\n",
       "      <td>75</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>6</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>no</td>\n",
       "      <td>2016-03-17 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>91074</td>\n",
       "      <td>2016-03-17 17:40:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2016-03-31 17:25:20</td>\n",
       "      <td>3600</td>\n",
       "      <td>small</td>\n",
       "      <td>2008</td>\n",
       "      <td>manual</td>\n",
       "      <td>69</td>\n",
       "      <td>fabia</td>\n",
       "      <td>90000</td>\n",
       "      <td>7</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>skoda</td>\n",
       "      <td>no</td>\n",
       "      <td>2016-03-31 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>60437</td>\n",
       "      <td>2016-04-06 10:17:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           DateCrawled  Price VehicleType  RegistrationYear Gearbox  Power  \\\n",
       "0  2016-03-24 11:52:17    480         NaN              1993  manual      0   \n",
       "1  2016-03-24 10:58:45  18300       coupe              2011  manual    190   \n",
       "2  2016-03-14 12:52:21   9800         suv              2004    auto    163   \n",
       "3  2016-03-17 16:54:04   1500       small              2001  manual     75   \n",
       "4  2016-03-31 17:25:20   3600       small              2008  manual     69   \n",
       "\n",
       "   Model  Kilometer  RegistrationMonth  FuelType       Brand NotRepaired  \\\n",
       "0   golf     150000                  0    petrol  volkswagen         NaN   \n",
       "1    NaN     125000                  5  gasoline        audi         yes   \n",
       "2  grand     125000                  8  gasoline        jeep         NaN   \n",
       "3   golf     150000                  6    petrol  volkswagen          no   \n",
       "4  fabia      90000                  7  gasoline       skoda          no   \n",
       "\n",
       "           DateCreated  NumberOfPictures  PostalCode             LastSeen  \n",
       "0  2016-03-24 00:00:00                 0       70435  2016-04-07 03:16:57  \n",
       "1  2016-03-24 00:00:00                 0       66954  2016-04-07 01:46:50  \n",
       "2  2016-03-14 00:00:00                 0       90480  2016-04-05 12:47:46  \n",
       "3  2016-03-17 00:00:00                 0       91074  2016-03-17 17:40:17  \n",
       "4  2016-03-31 00:00:00                 0       60437  2016-04-06 10:17:21  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    354369.000000\n",
       "mean       4416.656776\n",
       "std        4514.158514\n",
       "min           0.000000\n",
       "25%        1050.000000\n",
       "50%        2700.000000\n",
       "75%        6400.000000\n",
       "max       20000.000000\n",
       "Name: Price, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Price'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что в целевом признаке есть пропуски. Т.к. наша цель — научиться предсказывать стоимость, строчки с пропусками в соответствующем столбце вряд ли будут нам полезны. Можно их удалить. Крайние значения, вроде 1, оставим, поскольку точно не знаем их происхождения и в то же время хотим, чтобы наша модель умела работать с данными, которые встречаются в реальной жизни."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего удалено данных: 3.04%\n"
     ]
    }
   ],
   "source": [
    "data = data.drop(data[data['Price'] == 0].index)\n",
    "deleted = (1 - len(data) / 354369)\n",
    "print('Всего удалено данных: {:.2%}'.format(deleted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных присутствуют столбцы разных типов — здесь и категориальные, и численные данные. Также присутствуют даты, но в формате object. Два столбца — с датой скачивания объявления и с датой последнего просмотра — можно объединить в один: сколько дней объявление не просматривали до скачивания. Гипотетически, этот фактор может влиять на стоимость. Например, чем дольше объявление не просматривают, тем вероятнее что его цена высока. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['LastSeen'] = pd.to_datetime(data['LastSeen'], format='%Y-%m-%d %H:%M:%S') #переведем столбцы в специальный формат\n",
    "data['DateCrawled'] = pd.to_datetime(data['DateCrawled'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "data['TimeNoSee'] = data['LastSeen'].dt.date - data['DateCrawled'].dt.date #вычтем один из другого\n",
    "data['TimeNoSee'] = data['TimeNoSee'].apply(lambda x: int(str(x)[0:2])) #достанем числовое значение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1491966187422049"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Price'].corr(data['TimeNoSee'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Корреляция хоть и совсем маленькая, но прослеживается. Теперь можем удалить все столбцы с датами, включая день создания объявления — дальше они нам вряд ли понадобятся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['DateCrawled', 'DateCreated', 'LastSeen'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, на столбец с годом регистрации авто и на его значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    343597.000000\n",
       "mean       2004.089797\n",
       "std          78.413225\n",
       "min        1000.000000\n",
       "25%        1999.000000\n",
       "50%        2003.000000\n",
       "75%        2008.000000\n",
       "max        9999.000000\n",
       "Name: RegistrationYear, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"RegistrationYear\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13832"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[(data[\"RegistrationYear\"] < 1885) | (data[\"RegistrationYear\"] > 2016)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, в нём присутствуют аномальные значения, вроде 1000 и 9999. Заменим на 0 все значения меньше 1885 года (год появления авто) и выше 2016 (все объявления идут от этого года), поскольку их слишком много, чтобы удалять, а восстановить их достоверно мы не сможем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"RegistrationYear\"].where((data[\"RegistrationYear\"] > 1885) & (data[\"RegistrationYear\"] < 2016), 0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь перейдем к категориальным признакам и попробуем заменить их модой, найденной по набору связанных факторов. Например, в определении типа кузова нам поможет модель, год регистрации, коробка передач и некоторые другие признаки. Конечно, такое заполнение не дает 100% гарантию правильного ответа, но вероятность угадать будет точно выше 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VehicleType\n",
       "convertible     14\n",
       "coupe            1\n",
       "other            3\n",
       "sedan          276\n",
       "small           72\n",
       "wagon           53\n",
       "Name: VehicleType, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data['Model'] == 'golf') & (data['RegistrationYear'] == 2000) & (data['Gearbox'] == 'manual') &\n",
    "                (data['FuelType'] == 'petrol') & (data['Power'] == 75)].groupby('VehicleType')['VehicleType'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, авто с вышеуказанными признаками с вероятностью в 65% окажется седаном. Если похожих авто не найдется, поставим категорию 'unknown'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mode(x):\n",
    "    try:\n",
    "        return x.mode().iloc[0]\n",
    "    except:\n",
    "        return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 29s, sys: 2.1 s, total: 2min 32s\n",
      "Wall time: 2min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for column in ['VehicleType', 'Gearbox', 'FuelType']:\n",
    "    sect_cols = ['Model', 'VehicleType', 'Gearbox', 'FuelType', 'Power', 'RegistrationYear']\n",
    "    sect_cols.remove(column)\n",
    "    section = data[data[sect_cols[0]].notna() & data[sect_cols[1]].notna() & data[sect_cols[2]].notna() &\n",
    "                                data[sect_cols[3]].notna() & data[sect_cols[4]].notna()]\n",
    "    filler = section.groupby(sect_cols)[column].apply(lambda x: x.fillna(find_mode(x)))\n",
    "    data[column].fillna(filler, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.4 s, sys: 579 ms, total: 54.9 s\n",
      "Wall time: 56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sect_cols = ['Brand', 'VehicleType', 'Gearbox', 'FuelType', 'Power', 'RegistrationYear']\n",
    "section = data[data[sect_cols[0]].notna() & data[sect_cols[1]].notna() & data[sect_cols[2]].notna() &\n",
    "                                data[sect_cols[3]].notna() & data[sect_cols[4]].notna() & data[sect_cols[5]].notna()]\n",
    "mod_filler = section.groupby(sect_cols)[column].apply(lambda x: x.fillna(find_mode(x)))\n",
    "data['Model'].fillna(mod_filler, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь удалим все строки, в которых пропущены сразу все рассмотренные нами значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего удалено данных: 6.54%\n"
     ]
    }
   ],
   "source": [
    "data = data.drop(data[data['Gearbox'].isna() & data['VehicleType'].isna() &\n",
    "                                                          data['FuelType'].isna() & data['Model'].isna()].index)\n",
    "deleted += (1 - len(data) / 354369)\n",
    "print('Всего удалено данных: {:.2%}'.format(deleted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставшиеся пропуски в этих столбцах заменим на 'unknown'. Также этим значением заменим пропуски в столбце 'NotRepaired', поскольку никак иначе мы его восстановить не можем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['VehicleType', 'Gearbox', 'FuelType', 'Model', 'NotRepaired']:\n",
    "    data[column].fillna('unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перейдем к столбцу с почтовыми индексами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В нём 8135 уникальных значений\n"
     ]
    }
   ],
   "source": [
    "print('В нём {} уникальных значений'.format(len(data['PostalCode'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Т.к. географическое положение может влиять на стоимость авто, нам важно их сохранить, но, вероятно, лучше сократить кол-во уникальных значений, поскольку признак категориальный. Можно воспользоваться сторонним источником и заменить значения индексов на города. Загрузим справочник индексов. Он уже подготовлен."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>PlaceName</th>\n",
       "      <th>State</th>\n",
       "      <th>State Abbreviation</th>\n",
       "      <th>City</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1945</td>\n",
       "      <td>Kroppen</td>\n",
       "      <td>Brandenburg</td>\n",
       "      <td>BB</td>\n",
       "      <td>Oberspreewald-Lausitz</td>\n",
       "      <td>51.3833</td>\n",
       "      <td>13.8000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1968</td>\n",
       "      <td>Schipkau</td>\n",
       "      <td>Brandenburg</td>\n",
       "      <td>BB</td>\n",
       "      <td>Oberspreewald-Lausitz</td>\n",
       "      <td>51.5456</td>\n",
       "      <td>13.9121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1979</td>\n",
       "      <td>Lauchhammer</td>\n",
       "      <td>Brandenburg</td>\n",
       "      <td>BB</td>\n",
       "      <td>Oberspreewald-Lausitz</td>\n",
       "      <td>51.5000</td>\n",
       "      <td>13.7667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1983</td>\n",
       "      <td>GroЯrдschen</td>\n",
       "      <td>Brandenburg</td>\n",
       "      <td>BB</td>\n",
       "      <td>Oberspreewald-Lausitz</td>\n",
       "      <td>51.5833</td>\n",
       "      <td>14.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1987</td>\n",
       "      <td>Schwarzheide</td>\n",
       "      <td>Brandenburg</td>\n",
       "      <td>BB</td>\n",
       "      <td>Oberspreewald-Lausitz</td>\n",
       "      <td>51.4653</td>\n",
       "      <td>13.8680</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PostalCode     PlaceName        State State Abbreviation  \\\n",
       "0        1945       Kroppen  Brandenburg                 BB   \n",
       "1        1968      Schipkau  Brandenburg                 BB   \n",
       "2        1979   Lauchhammer  Brandenburg                 BB   \n",
       "3        1983   GroЯrдschen  Brandenburg                 BB   \n",
       "4        1987  Schwarzheide  Brandenburg                 BB   \n",
       "\n",
       "                    City  Latitude  Longitude  Unnamed: 7  \n",
       "0  Oberspreewald-Lausitz   51.3833    13.8000         NaN  \n",
       "1  Oberspreewald-Lausitz   51.5456    13.9121         NaN  \n",
       "2  Oberspreewald-Lausitz   51.5000    13.7667         NaN  \n",
       "3  Oberspreewald-Lausitz   51.5833    14.0000         NaN  \n",
       "4  Oberspreewald-Lausitz   51.4653    13.8680         NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    postcodes = pd.read_csv('de_postal_codes.csv')\n",
    "except:\n",
    "    postcodes = pd.read_csv('https://raw.githubusercontent.com/julialysova/Postal-codes/main/de_postal_codes.csv')\n",
    "postcodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "postcodes['PostalCode'] = postcodes['PostalCode'].astype('int64') #переведем индексы в числовое значение\n",
    "postcodes.set_index('PostalCode', inplace=True) #для простого поиска заменим указатель на столбец индексов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_city(postal, table):\n",
    "    try:\n",
    "        return table.loc[postal, 'City']\n",
    "    except:\n",
    "        return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 341981 entries, 0 to 354368\n",
      "Data columns (total 14 columns):\n",
      "Price                341981 non-null int64\n",
      "VehicleType          341981 non-null object\n",
      "RegistrationYear     341981 non-null int64\n",
      "Gearbox              341981 non-null object\n",
      "Power                341981 non-null int64\n",
      "Model                341981 non-null object\n",
      "Kilometer            341981 non-null int64\n",
      "RegistrationMonth    341981 non-null int64\n",
      "FuelType             341981 non-null object\n",
      "Brand                341981 non-null object\n",
      "NotRepaired          341981 non-null object\n",
      "NumberOfPictures     341981 non-null int64\n",
      "TimeNoSee            341981 non-null int64\n",
      "City                 341981 non-null object\n",
      "dtypes: int64(7), object(7)\n",
      "memory usage: 39.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data['City'] = data['PostalCode'].apply(find_city, table=postcodes) #заменяем все на города\n",
    "data = data.drop(['PostalCode'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "421"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['City'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь у нас 421 уникальное значение в столбце, что проще предсказать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном шаге мы произвели обработку данных, заполнили пропуски и преобразовали некоторые признаки для удобства дальнейшей работы. В следующем шаге мы преобразуем данные так, чтобы на них можно было обучить модель, и попробуем поработать с разными моделями."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перейдем к выделению различных групп признаков. У нас есть категориальные, которые мы преобразуем по методу OHE; порядковые — Ordinal Encoding и численные, которые мы будем маштабировать. Модель и город мы отнесем к порядковым, поскольку они слишком увеличат размерность, если применить к ним OHE, и моделям будет сложно справиться с данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['VehicleType', 'Gearbox', 'FuelType', 'Brand', 'NotRepaired']\n",
    "numerical = ['Power', 'Kilometer', 'NumberOfPictures', 'TimeNoSee']\n",
    "ordinal = ['Model', 'City', 'RegistrationYear']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на фичи и целевой признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data['Price']\n",
    "features = data.drop(['Price'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    341981.000000\n",
       "mean       4568.749469\n",
       "std        4517.229384\n",
       "min           1.000000\n",
       "25%        1200.000000\n",
       "50%        2900.000000\n",
       "75%        6500.000000\n",
       "max       20000.000000\n",
       "Name: Price, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Произведем преобразование категориальных признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_categorical = pd.get_dummies(features[categorical], drop_first=True)\n",
    "features[features_categorical.columns] = features_categorical\n",
    "features = features.drop(categorical, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее преобразуем порядковые."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder()\n",
    "encoder.fit(features[ordinal])\n",
    "features[ordinal] = encoder.transform(features[ordinal])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размеры обучающей выборки: (256485, 66)\n",
      "Размеры валидационной выборки: (85496, 66)\n"
     ]
    }
   ],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "                                                features, target, test_size=0.25, random_state=12345)\n",
    "\n",
    "print('Размеры обучающей выборки:', features_train.shape)\n",
    "print('Размеры валидационной выборки:', features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отмасштабируем признаки для обучающей и тестовой выборки отдельно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train)\n",
    "\n",
    "features_train_scaled = scaler.transform(features_train)\n",
    "features_test_scaled = scaler.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перейдем к обучению моделей. Для проверки их качества мы будем использовать метрику RMSE, для вычисления которой создадим специальную функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(pred, target):\n",
    "    return np.sqrt(mean_squared_error(pred, target))\n",
    "\n",
    "RMSE_scorer = make_scorer(rmse, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем обучение с решающего дерева и проверим, как быстро и как качественно он справляется с нашими данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.4min finished\n"
     ]
    }
   ],
   "source": [
    "tree_parameters = {'max_depth':range(1,20,2)}\n",
    "tree = DecisionTreeRegressor(random_state=12345)\n",
    "tree_grid = GridSearchCV(tree, tree_parameters, cv=5, verbose=1, iid=False, scoring=RMSE_scorer)\n",
    "\n",
    "tree_best = tree_grid.fit(features_train_scaled, target_train)\n",
    "tree_predictions = tree_best.predict(features_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1661.7670449349407"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_rmse = rmse(target_train, tree_predictions)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ошибка на обучающих данных составила 1661,767, а время работы модели — 2,5 минуты на 50 обучений. Проверим результат модели на тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.9 ms, sys: 101 µs, total: 36 ms\n",
      "Wall time: 34.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1949.9240271824424"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tree_predictions_test = tree_best.predict(features_test_scaled)\n",
    "tree_rmse_test = rmse(target_test, tree_predictions_test)\n",
    "tree_rmse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Присутствует переобучение, но ошибка не превышает 2 тыс. Однако такой показатель всё еще кажется большим, поскольку превышает стоимость 25% автомобилей в нашей подборке. Теперь посмотрим на случайный лес."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 40 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed: 10.0min finished\n"
     ]
    }
   ],
   "source": [
    "forest_parameters = {'max_depth':range(1,11,2), 'n_estimators':range(1,40,10), 'max_leaf_nodes':[10,50]}\n",
    "forest = RandomForestRegressor(random_state=12345)\n",
    "forest_grid = GridSearchCV(forest, forest_parameters, scoring=RMSE_scorer, cv=2, verbose=1, iid=False)\n",
    "\n",
    "forest_best = forest_grid.fit(features_train_scaled, target_train)\n",
    "forest_predictions = forest_best.predict(features_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1661.7670449349407"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_rmse = rmse(target_train, tree_predictions)\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 118 ms, sys: 34 µs, total: 118 ms\n",
      "Wall time: 121 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2314.2103890417907"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "forest_predictions_test = forest_best.predict(features_test_scaled)\n",
    "forest_rmse_test = rmse(target_test, forest_predictions_test)\n",
    "forest_rmse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Случайный лес дал такой же показатель на обучающих данных, что и решающее дерево, но переобучение сильнее, поскольку на тестовых данных ошибка составила 2314,21. Время для 80 обучений — 9,7 мин."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь посмотрим, как с данными справится бустинг LightGBM. Разделим и преобразуем заново, так как для категориальных признаков мы будем использовать встроенную в библиотеку lgb функцию работы с ними. Для этого их всё же придется преобразовать в численные (порядковые)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_lgb = data.drop('Price', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.fit(features_lgb[categorical + ordinal])\n",
    "features_lgb[categorical + ordinal] = encoder.transform(features_lgb[categorical + ordinal])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размеры обучающей выборки: (256485, 13)\n",
      "Размеры валидационной выборки: (85496, 13)\n"
     ]
    }
   ],
   "source": [
    "features_train_lgb, features_test_lgb, target_train_lgb, target_test_lgb = train_test_split(\n",
    "                                                features_lgb, target, test_size=0.25, random_state=12345)\n",
    "\n",
    "print('Размеры обучающей выборки:', features_train_lgb.shape)\n",
    "print('Размеры валидационной выборки:', features_test_lgb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_parameters = {'num_leaves': [30, 100], 'learning_rate': [0.1, 0.03], 'max_depth': [10, 50]}\n",
    "cat = categorical + ['Model','City']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1295: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['Brand', 'City', 'FuelType', 'Gearbox', 'Model', 'NotRepaired', 'VehicleType']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1295: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['Brand', 'City', 'FuelType', 'Gearbox', 'Model', 'NotRepaired', 'VehicleType']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1295: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['Brand', 'City', 'FuelType', 'Gearbox', 'Model', 'NotRepaired', 'VehicleType']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1295: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['Brand', 'City', 'FuelType', 'Gearbox', 'Model', 'NotRepaired', 'VehicleType']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1295: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['Brand', 'City', 'FuelType', 'Gearbox', 'Model', 'NotRepaired', 'VehicleType']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1295: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['Brand', 'City', 'FuelType', 'Gearbox', 'Model', 'NotRepaired', 'VehicleType']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1295: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['Brand', 'City', 'FuelType', 'Gearbox', 'Model', 'NotRepaired', 'VehicleType']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1295: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['Brand', 'City', 'FuelType', 'Gearbox', 'Model', 'NotRepaired', 'VehicleType']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1295: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['Brand', 'City', 'FuelType', 'Gearbox', 'Model', 'NotRepaired', 'VehicleType']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1295: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['Brand', 'City', 'FuelType', 'Gearbox', 'Model', 'NotRepaired', 'VehicleType']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1295: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['Brand', 'City', 'FuelType', 'Gearbox', 'Model', 'NotRepaired', 'VehicleType']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1295: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['Brand', 'City', 'FuelType', 'Gearbox', 'Model', 'NotRepaired', 'VehicleType']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1295: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['Brand', 'City', 'FuelType', 'Gearbox', 'Model', 'NotRepaired', 'VehicleType']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1295: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['Brand', 'City', 'FuelType', 'Gearbox', 'Model', 'NotRepaired', 'VehicleType']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1295: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['Brand', 'City', 'FuelType', 'Gearbox', 'Model', 'NotRepaired', 'VehicleType']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1295: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['Brand', 'City', 'FuelType', 'Gearbox', 'Model', 'NotRepaired', 'VehicleType']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed: 12.9min finished\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1295: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['Brand', 'City', 'FuelType', 'Gearbox', 'Model', 'NotRepaired', 'VehicleType']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 1s, sys: 4.15 s, total: 13min 5s\n",
      "Wall time: 13min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise-deprecating',\n",
       "             estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None,\n",
       "                                     colsample_bytree=1.0,\n",
       "                                     importance_type='split', learning_rate=0.1,\n",
       "                                     max_depth=-1, min_child_samples=20,\n",
       "                                     min_child_weight=0.001, min_split_gain=0.0,\n",
       "                                     n_estimators=100, n_jobs=-1, num_leaves=31,\n",
       "                                     objective=None, random_state=12345,\n",
       "                                     reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "                                     subsample=1.0, subsample_for_bin=200000,\n",
       "                                     subsample_freq=0),\n",
       "             iid=False, n_jobs=None,\n",
       "             param_grid={'learning_rate': [0.1, 0.03], 'max_depth': [10, 50],\n",
       "                         'num_leaves': [30, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=make_scorer(rmse, greater_is_better=False), verbose=1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lgbm_reg = lgb.LGBMRegressor(random_state=12345)\n",
    "lgbm_grid = GridSearchCV(lgbm_reg, lgbm_parameters, scoring=RMSE_scorer, cv=2, verbose=1, iid=False)\n",
    "\n",
    "lgbm_trained = lgbm_grid.fit(features_train_lgb, target_train_lgb, categorical_feature=cat)\n",
    "\n",
    "lgbm_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1364.3102970490654"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_predictions = lgbm_trained.predict(features_train_lgb)\n",
    "lgbm_rmse = rmse(target_train_lgb, lgbm_predictions)\n",
    "lgbm_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.17 s, sys: 0 ns, total: 2.17 s\n",
      "Wall time: 2.19 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1605.813593869075"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lgbm_predictions_test = lgbm_trained.predict(features_test_lgb)\n",
    "\n",
    "lgbm_rmse_test = rmse(target_test_lgb, lgbm_predictions_test)\n",
    "lgbm_rmse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученный результат как на обучении, так и на тесте лучше, чем у предыдущих моделей (1364,31 и 1605,81 соответственно). Время на 16 итераций - 8 мин 30 сек."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом шаге мы обучили три разные модели, получили результаты и время обучения каждой модели. В следующем шаге проанализируем полученные результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы провели обучение 3 регрессионных моделей: решающего дерева, случайного леса и градиентного бустинга. \n",
    "Самым быстрым было решающее дерево — 3 секунды на 1 итерацию. Результат на тестовой выборке не превысил 2 тыс.\n",
    "Решающему лесу для одного обучения понадобилось 7,3 секунд, при этом ошибка на тестовой выборке превысила 2,3 тыс.\n",
    "Самая маленькая ошибка (1,6 тыс.) была получена с помощью градиентного бустинга. При этом он был самым медленным — на одну итерацию ушло 30 секунд. Самое быстрое предсказание также было сделано с помощью решающего дерева.\n",
    "Если ставить на весы и скорость и качество предсказания, то лучше обратиться к решающему дереву — оно делает относительно стабильные предсказания и делает это быстрее остальных испытанных моделей. Несмотря на то, что градиентный бустинг показывает наименьшую ошибку, он не подходит к запросу нашего клиента, которому нужно давать быстрые предсказания пользователям сервиса."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Оглавление",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
